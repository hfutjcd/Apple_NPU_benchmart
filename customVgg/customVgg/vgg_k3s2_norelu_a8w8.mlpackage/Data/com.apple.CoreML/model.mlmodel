	◊

input*
@¿¿êÄR
var_63*
ÄêÄ¢°¢3
#com.github.apple.coremltools.sourcetorch==2.5.1¢+
$com.github.apple.coremltools.version8.1¢:
+com.github.apple.coremltools.source_dialectTorchScript≤öuïu
mainåu
)
input 



@
¿
¿CoreML8’t
CoreML8…tvar_63j
const
input_1_pad_type_0
*(
name 

"
input_1_pad_type_0*
val


"
customn
const
input_1_pad_0


*#
name

"
input_1_pad_0*!
val





t
const!
input_1_strides_0


*'
name

"
input_1_strides_0*
val




x
const#
input_1_dilations_0


*)
name!

"
input_1_dilations_0*
val




a
const
input_1_groups_0
*&
name

"
input_1_groups_0*
val


Õ
constexpr_blockwise_shift_scaleQ
dataI
GE

Ä
@

*"
@model_path/weights/weight.bin@T
scaleK
IG


Ä


*$
@model_path/weights/weight.binÄÅF
#features_0_weight_to_fp16_quantized


Ä
@

*9
name1
)
'"%
#features_0_weight_to_fp16_quantizedû
const(
features_0_bias_to_fp16


Ä*-
name%

"
features_0_bias_to_fp16*<
val5


Ä*$
@model_path/weights/weight.bin¿âf
const
quantize_0_scale_0

*(
name 

"
quantize_0_scale_0*
val


:
Ü)v
const!
quantize_0_output_dtype_0
*/
name'

"
quantize_0_output_dtype_0*
val


"
int8¿
quantize-
output_dtype

quantize_0_output_dtype_0
scale

quantize_0_scale_0
input	

input.

quantize_0 


@
¿
¿* 
name

"

quantize_0j
const
dequantize_0_scale_0

**
name"

"
dequantize_0_scale_0*
val


:
Ü)û

dequantize!
scale

dequantize_0_scale_0
input


quantize_00
dequantize_0 



@
¿
¿*"
name

"
dequantize_0¸
conv1
weight'
%
#features_0_weight_to_fp16_quantized$
	dilations

input_1_dilations_0
groups

input_1_groups_0
pad

input_1_pad_0#
bias

features_0_bias_to_fp16 
strides

input_1_strides_0
x

dequantize_0"
pad_type

input_1_pad_type_06
input_1_cast_fp16!



Ä
‡
‡*'
name

"
input_1_cast_fp16j
const
input_3_pad_type_0
*(
name 

"
input_3_pad_type_0*
val


"
customn
const
input_3_pad_0


*#
name

"
input_3_pad_0*!
val





t
const!
input_3_strides_0


*'
name

"
input_3_strides_0*
val




x
const#
input_3_dilations_0


*)
name!

"
input_3_dilations_0*
val




a
const
input_3_groups_0
*&
name

"
input_3_groups_0*
val


“
constexpr_blockwise_shift_scaleT
dataL
JH 

Ä
Ä

*$
@model_path/weights/weight.binÄíU
scaleL
JH


Ä


*%
@model_path/weights/weight.bin¿í¢G
#features_1_weight_to_fp16_quantized 


Ä
Ä

*9
name1
)
'"%
#features_1_weight_to_fp16_quantizedü
const(
features_1_bias_to_fp16


Ä*-
name%

"
features_1_bias_to_fp16*=
val6


Ä*%
@model_path/weights/weight.binÄõ¢f
const
quantize_1_scale_0

*(
name 

"
quantize_1_scale_0*
val


:
ò&v
const!
quantize_1_output_dtype_0
*/
name'

"
quantize_1_output_dtype_0*
val


"
int8Õ
quantize-
output_dtype

quantize_1_output_dtype_0
scale

quantize_1_scale_0
input

input_1_cast_fp16/

quantize_1!


Ä
‡
‡* 
name

"

quantize_1j
const
dequantize_1_scale_0

**
name"

"
dequantize_1_scale_0*
val


:
ò&ü

dequantize!
scale

dequantize_1_scale_0
input


quantize_11
dequantize_1!



Ä
‡
‡*"
name

"
dequantize_1˙
conv1
weight'
%
#features_1_weight_to_fp16_quantized$
	dilations

input_3_dilations_0
groups

input_3_groups_0
pad

input_3_pad_0#
bias

features_1_bias_to_fp16 
strides

input_3_strides_0
x

dequantize_1"
pad_type

input_3_pad_type_04
input_3_cast_fp16



Ä
p
p*'
name

"
input_3_cast_fp16j
const
input_5_pad_type_0
*(
name 

"
input_5_pad_type_0*
val


"
customn
const
input_5_pad_0


*#
name

"
input_5_pad_0*!
val





t
const!
input_5_strides_0


*'
name

"
input_5_strides_0*
val




x
const#
input_5_dilations_0


*)
name!

"
input_5_dilations_0*
val




a
const
input_5_groups_0
*&
name

"
input_5_groups_0*
val


”
constexpr_blockwise_shift_scaleU
dataM
KI 

Ä
Ä

*%
@model_path/weights/weight.bin¿£¢U
scaleL
JH


Ä


*%
@model_path/weights/weight.binÄ§≤G
#features_2_weight_to_fp16_quantized 


Ä
Ä

*9
name1
)
'"%
#features_2_weight_to_fp16_quantizedü
const(
features_2_bias_to_fp16


Ä*-
name%

"
features_2_bias_to_fp16*=
val6


Ä*%
@model_path/weights/weight.bin¿¨≤f
const
quantize_2_scale_0

*(
name 

"
quantize_2_scale_0*
val


:
#v
const!
quantize_2_output_dtype_0
*/
name'

"
quantize_2_output_dtype_0*
val


"
int8À
quantize-
output_dtype

quantize_2_output_dtype_0
scale

quantize_2_scale_0
input

input_3_cast_fp16-

quantize_2


Ä
p
p* 
name

"

quantize_2j
const
dequantize_2_scale_0

**
name"

"
dequantize_2_scale_0*
val


:
#ù

dequantize!
scale

dequantize_2_scale_0
input


quantize_2/
dequantize_2



Ä
p
p*"
name

"
dequantize_2˙
conv1
weight'
%
#features_2_weight_to_fp16_quantized$
	dilations

input_5_dilations_0
groups

input_5_groups_0
pad

input_5_pad_0#
bias

features_2_bias_to_fp16 
strides

input_5_strides_0
x

dequantize_2"
pad_type

input_5_pad_type_04
input_5_cast_fp16



Ä
8
8*'
name

"
input_5_cast_fp16j
const
input_7_pad_type_0
*(
name 

"
input_7_pad_type_0*
val


"
customn
const
input_7_pad_0


*#
name

"
input_7_pad_0*!
val





t
const!
input_7_strides_0


*'
name

"
input_7_strides_0*
val




x
const#
input_7_dilations_0


*)
name!

"
input_7_dilations_0*
val




a
const
input_7_groups_0
*&
name

"
input_7_groups_0*
val


”
constexpr_blockwise_shift_scaleU
dataM
KI 

Ä
Ä

*%
@model_path/weights/weight.binÄµ≤U
scaleL
JH


Ä


*%
@model_path/weights/weight.bin¿µ¬G
#features_3_weight_to_fp16_quantized 


Ä
Ä

*9
name1
)
'"%
#features_3_weight_to_fp16_quantizedü
const(
features_3_bias_to_fp16


Ä*-
name%

"
features_3_bias_to_fp16*=
val6


Ä*%
@model_path/weights/weight.binÄæ¬f
const
quantize_3_scale_0

*(
name 

"
quantize_3_scale_0*
val


:
ñv
const!
quantize_3_output_dtype_0
*/
name'

"
quantize_3_output_dtype_0*
val


"
int8À
quantize-
output_dtype

quantize_3_output_dtype_0
scale

quantize_3_scale_0
input

input_5_cast_fp16-

quantize_3


Ä
8
8* 
name

"

quantize_3j
const
dequantize_3_scale_0

**
name"

"
dequantize_3_scale_0*
val


:
ñù

dequantize!
scale

dequantize_3_scale_0
input


quantize_3/
dequantize_3



Ä
8
8*"
name

"
dequantize_3˙
conv1
weight'
%
#features_3_weight_to_fp16_quantized$
	dilations

input_7_dilations_0
groups

input_7_groups_0
pad

input_7_pad_0#
bias

features_3_bias_to_fp16 
strides

input_7_strides_0
x

dequantize_3"
pad_type

input_7_pad_type_04
input_7_cast_fp16



Ä

*'
name

"
input_7_cast_fp16j
const
input_9_pad_type_0
*(
name 

"
input_9_pad_type_0*
val


"
customn
const
input_9_pad_0


*#
name

"
input_9_pad_0*!
val





t
const!
input_9_strides_0


*'
name

"
input_9_strides_0*
val




x
const#
input_9_dilations_0


*)
name!

"
input_9_dilations_0*
val




a
const
input_9_groups_0
*&
name

"
input_9_groups_0*
val


”
constexpr_blockwise_shift_scaleU
dataM
KI 

Ä
Ä

*%
@model_path/weights/weight.bin¿∆¬U
scaleL
JH


Ä


*%
@model_path/weights/weight.binÄ«“G
#features_4_weight_to_fp16_quantized 


Ä
Ä

*9
name1
)
'"%
#features_4_weight_to_fp16_quantizedü
const(
features_4_bias_to_fp16


Ä*-
name%

"
features_4_bias_to_fp16*=
val6


Ä*%
@model_path/weights/weight.bin¿œ“f
const
quantize_4_scale_0

*(
name 

"
quantize_4_scale_0*
val


:
Jv
const!
quantize_4_output_dtype_0
*/
name'

"
quantize_4_output_dtype_0*
val


"
int8À
quantize-
output_dtype

quantize_4_output_dtype_0
scale

quantize_4_scale_0
input

input_7_cast_fp16-

quantize_4


Ä

* 
name

"

quantize_4j
const
dequantize_4_scale_0

**
name"

"
dequantize_4_scale_0*
val


:
Jù

dequantize!
scale

dequantize_4_scale_0
input


quantize_4/
dequantize_4



Ä

*"
name

"
dequantize_4˙
conv1
weight'
%
#features_4_weight_to_fp16_quantized$
	dilations

input_9_dilations_0
groups

input_9_groups_0
pad

input_9_pad_0#
bias

features_4_bias_to_fp16 
strides

input_9_strides_0
x

dequantize_4"
pad_type

input_9_pad_type_04
input_9_cast_fp16



Ä

*'
name

"
input_9_cast_fp16f
const
input_pad_type_0
*&
name

"
input_pad_type_0*
val


"
customj
const
input_pad_0


*!
name

"
input_pad_0*!
val





p
const
input_strides_0


*%
name

"
input_strides_0*
val




t
const!
input_dilations_0


*'
name

"
input_dilations_0*
val




]
const
input_groups_0
*$
name

"
input_groups_0*
val


”
constexpr_blockwise_shift_scaleU
dataM
KI 

Ä
Ä

*%
@model_path/weights/weight.binÄÿ“U
scaleL
JH


Ä


*%
@model_path/weights/weight.bin¿ÿ‚G
#features_5_weight_to_fp16_quantized 


Ä
Ä

*9
name1
)
'"%
#features_5_weight_to_fp16_quantizedü
const(
features_5_bias_to_fp16


Ä*-
name%

"
features_5_bias_to_fp16*=
val6


Ä*%
@model_path/weights/weight.binÄ·‚f
const
quantize_5_scale_0

*(
name 

"
quantize_5_scale_0*
val


:
dv
const!
quantize_5_output_dtype_0
*/
name'

"
quantize_5_output_dtype_0*
val


"
int8À
quantize-
output_dtype

quantize_5_output_dtype_0
scale

quantize_5_scale_0
input

input_9_cast_fp16-

quantize_5


Ä

* 
name

"

quantize_5j
const
dequantize_5_scale_0

**
name"

"
dequantize_5_scale_0*
val


:
dù

dequantize!
scale

dequantize_5_scale_0
input


quantize_5/
dequantize_5



Ä

*"
name

"
dequantize_5Ï
conv1
weight'
%
#features_5_weight_to_fp16_quantized"
	dilations

input_dilations_0
groups

input_groups_0
pad

input_pad_0#
bias

features_5_bias_to_fp16
strides

input_strides_0
x

dequantize_5 
pad_type

input_pad_type_02
input_cast_fp16



Ä

*%
name

"
input_cast_fp16g
const
var_63_pad_type_0
*&
name

"
op_63_pad_type_0*
val


"
customk
const
var_63_pad_0


*!
name

"
op_63_pad_0*!
val





q
const 
var_63_strides_0


*%
name

"
op_63_strides_0*
val




u
const"
var_63_dilations_0


*'
name

"
op_63_dilations_0*
val




^
const
var_63_groups_0
*$
name

"
op_63_groups_0*
val


”
constexpr_blockwise_shift_scaleU
dataM
KI 

Ä
Ä

*%
@model_path/weights/weight.bin¿È‚U
scaleL
JH


Ä


*%
@model_path/weights/weight.binÄÍÚG
#features_6_weight_to_fp16_quantized 


Ä
Ä

*9
name1
)
'"%
#features_6_weight_to_fp16_quantizedü
const(
features_6_bias_to_fp16


Ä*-
name%

"
features_6_bias_to_fp16*=
val6


Ä*%
@model_path/weights/weight.bin¿ÚÚf
const
quantize_6_scale_0

*(
name 

"
quantize_6_scale_0*
val


:
dv
const!
quantize_6_output_dtype_0
*/
name'

"
quantize_6_output_dtype_0*
val


"
int8…
quantize-
output_dtype

quantize_6_output_dtype_0
scale

quantize_6_scale_0
input

input_cast_fp16-

quantize_6


Ä

* 
name

"

quantize_6j
const
dequantize_6_scale_0

**
name"

"
dequantize_6_scale_0*
val


:
dù

dequantize!
scale

dequantize_6_scale_0
input


quantize_6/
dequantize_6



Ä

*"
name

"
dequantize_6Ë
conv1
weight'
%
#features_6_weight_to_fp16_quantized#
	dilations

var_63_dilations_0
groups

var_63_groups_0
pad

var_63_pad_0#
bias

features_6_bias_to_fp16
strides

var_63_strides_0
x

dequantize_6!
pad_type

var_63_pad_type_0)
var_63



Ä

*%
name

"
op_63_cast_fp16